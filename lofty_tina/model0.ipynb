{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba7137a7-ed80-4f06-b019-95734a739154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from -r requirements.txt (line 1)) (2.5.1+cpu)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from -r requirements.txt (line 2)) (6.29.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (8.36.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (6.5)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipykernel->-r requirements.txt (line 2)) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 2)) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 2)) (307)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 2)) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\mruiz\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 2)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc4bb9d7-64ca-42b8-8a6a-ac12b20fcbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import subprocess\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import onnx\n",
    "import shutil\n",
    "from timeit import default_timer as timer\n",
    "import vai_q_onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "436a0fa1-d892-443c-9aa1-73e48c2e1271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APU Type: PHX/HPT\n"
     ]
    }
   ],
   "source": [
    "def get_apu_info():\n",
    "    # Run pnputil as a subprocess to enumerate PCI devices\n",
    "    command = r'pnputil /enum-devices /bus PCI /deviceids '\n",
    "    process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    stdout, stderr = process.communicate()\n",
    "    # Check for supported Hardware IDs\n",
    "    apu_type = ''\n",
    "    if 'PCI\\\\VEN_1022&DEV_1502&REV_00' in stdout.decode(): apu_type = 'PHX/HPT'\n",
    "    if 'PCI\\\\VEN_1022&DEV_17F0&REV_00' in stdout.decode(): apu_type = 'STX'\n",
    "    if 'PCI\\\\VEN_1022&DEV_17F0&REV_10' in stdout.decode(): apu_type = 'STX'\n",
    "    if 'PCI\\\\VEN_1022&DEV_17F0&REV_11' in stdout.decode(): apu_type = 'STX'\n",
    "    return apu_type\n",
    "apu_type = get_apu_info()\n",
    "print(f\"APU Type: {apu_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "330abe27-41c9-4a89-8a73-f754eba4c440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for PHX/HPT\n",
      "XLNX_VART_FIRMWARE= /home/user/ryzen_ai-1.4.0\\voe-4.0-win_amd64\\xclbins\\phoenix\\1x4.xclbin\n",
      "NUM_OF_DPU_RUNNERS= 1\n",
      "XLNX_TARGET_NAME= AMD_AIE2_Nx4_Overlay\n"
     ]
    }
   ],
   "source": [
    "def set_environment_variable(apu_type):\n",
    "\n",
    "    install_dir = os.environ['RYZEN_AI_INSTALLATION_PATH']\n",
    "    match apu_type:\n",
    "        case 'PHX/HPT':\n",
    "            print(\"Setting environment for PHX/HPT\")\n",
    "            os.environ['XLNX_VART_FIRMWARE']= os.path.join(install_dir, 'voe-4.0-win_amd64', 'xclbins', 'phoenix', '1x4.xclbin')\n",
    "            os.environ['NUM_OF_DPU_RUNNERS']='1'\n",
    "            os.environ['XLNX_TARGET_NAME']='AMD_AIE2_Nx4_Overlay'\n",
    "        case 'STX':\n",
    "            print(\"Setting environment for STX\")\n",
    "            os.environ['XLNX_VART_FIRMWARE']= os.path.join(install_dir, 'voe-4.0-win_amd64', 'xclbins', 'strix', 'AMD_AIE2P_Nx4_Overlay.xclbin')\n",
    "            os.environ['NUM_OF_DPU_RUNNERS']='1'\n",
    "            os.environ['XLNX_TARGET_NAME']='AMD_AIE2_Nx4_Overlay'\n",
    "        case _:\n",
    "            print(\"Unrecognized APU type. Exiting.\")\n",
    "            exit()\n",
    "    print('XLNX_VART_FIRMWARE=', os.environ['XLNX_VART_FIRMWARE'])\n",
    "    print('NUM_OF_DPU_RUNNERS=', os.environ['NUM_OF_DPU_RUNNERS'])\n",
    "    print('XLNX_TARGET_NAME=', os.environ['XLNX_TARGET_NAME'])\n",
    "\n",
    "os.environ['RYZEN_AI_INSTALLATION_PATH'] = \"/home/user/ryzen_ai-1.4.0\"\n",
    "\n",
    "set_environment_variable(apu_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca0cd8f-f27e-42df-88b3-afd5adf43853",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acc3877d-657d-4262-850e-7c5d16bbc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedSumConv1D(nn.Module):\n",
    "    def __init__(self, weights: torch.Tensor):\n",
    "        super().__init__()\n",
    "        P = weights.shape[1]\n",
    "        self.conv1d = nn.Conv1d(3, P, kernel_size=1, bias=False)\n",
    "        self.conv1d.weight.data = weights.T.unsqueeze(-1)\n",
    "        self.conv1d.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1d(x)          # (1, P, M)\n",
    "        return out.squeeze(0) # torch.mul(out, scale).squeeze(0)  # (P, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c2002d0a-f61b-4761-8ce1-bdab1635f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.cos(x)\n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05e212a5-b63d-4582-8c6f-2accba49ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElementwiseMultiply(nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return torch.mul(x, y)\n",
    "\n",
    "class Subtract(nn.Module):\n",
    "    def forward(self, x, y):\n",
    "        return torch.sub(x, y)\n",
    "\n",
    "class Average(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.pool = nn.AvgPool1d(kernel_size=M)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.pool(x) # (M, 1)\n",
    "        out = out.squeeze(-1) # (M,)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dab53cfa-478c-4380-8aca-ca4d0796eed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealImagDiffAverage(nn.Module):\n",
    "    def __init__(self, M):\n",
    "        super().__init__()\n",
    "        self.cos = CosineLayer()\n",
    "        self.sin = SineLayer()\n",
    "        self.mul = ElementwiseMultiply()\n",
    "        self.sub = Subtract()\n",
    "        # self.avg = Average(M)\n",
    "\n",
    "    def forward(self, x, input1, input2, scale):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape (P, M)\n",
    "        input1: Tensor of shape (M) - multiplier for the real part (cos)\n",
    "        input2: Tensor of shape (M) - multiplier for the imaginary part (sin)\n",
    "\n",
    "        Output: Tensor of shape (P) - final result after the operations\n",
    "        \"\"\"\n",
    "        # Multiply by the scale factor\n",
    "        A = self.mul(x, scale.view(-1, 1))\n",
    "\n",
    "        # Apply cosine and sine element-wise to each row of x\n",
    "        real = self.cos(A)  # shape: (P, M)\n",
    "        imag = self.sin(A)   # shape: (P, M)\n",
    "\n",
    "        # Multiply element-wise with input1 and input2 respectively\n",
    "        R = self.mul(real, input1)  # shape: (P, M)\n",
    "        I = self.mul(imag, input2)  # shape: (P, M)\n",
    "\n",
    "        # Subtract R and I element-wise\n",
    "        diff = self.sub(R, I)  # shape: (P, M)\n",
    "\n",
    "        # Average the result over the M dimension (mean of each row)\n",
    "        return torch.mean(diff, dim=1)  # shape: (P,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "932cf212-00cb-4627-9a37-b839186d3113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModule(nn.Module):\n",
    "    def __init__(self, weights: torch.Tensor, M):\n",
    "        super().__init__()\n",
    "        self.weighted_sum = WeightedSumConv1D(weights)\n",
    "        self.real_imag = RealImagDiffAverage(M)\n",
    "\n",
    "    def forward(self, x, input1, input2, scale):\n",
    "        out = self.weighted_sum(x)\n",
    "        return self.real_imag(out, input1, input2, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1747bd86-3b80-46aa-8345-fd3f71a8bbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files extracted to: unzipped_files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "extract_dir = \"unzipped_files\"  # or any directory you want to extract to\n",
    "output = \"unzipped_files/inputfiles.zip\"\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "print(f\"Files extracted to: {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a62e88c5-00c0-4621-8c19-d994603b6a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visibilities\n",
      "visR: (96, 96) visI: (96, 96)\n",
      "Baselines\n",
      "u: (96, 96) v: (96, 96) w: (96, 96)\n",
      "Frequency\n",
      "freq: (1,) = 58593750.0\n",
      "LMN\n",
      "l: (128, 128) m: (128, 128) n: (128, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "SPEED_OF_LIGHT = 299792458.0\n",
    "\n",
    "def read_npy_data(path):\n",
    "    baselines = np.load(f\"{path}/baselines.npy\")\n",
    "    visibilities = np.load(f\"{path}/vis.npy\")[0]\n",
    "    frequency = np.load(f\"{path}/freq.npy\")\n",
    "    return (frequency, visibilities, baselines)\n",
    "npix_l, npix_m = 128, 128\n",
    "frequency, visibilities, baselines = read_npy_data(path=extract_dir)\n",
    "visR, visI = np.real(visibilities), np.imag(visibilities)\n",
    "u, v, w = [baselines[:, :, i] for i in range(3)]\n",
    "l, m = np.meshgrid(np.linspace(-1, 1, npix_l), np.linspace(1, -1, npix_m))\n",
    "with np.errstate(all='ignore'):\n",
    "    n = np.sqrt(1 - l**2 - m**2) - 1\n",
    "    nan_mask = np.isnan(n)\n",
    "    n = np.nan_to_num(n) # or else it doesnt work\n",
    "print(\"Visibilities\")\n",
    "print(\"visR:\", visR.shape, \"visI:\",  visI.shape)\n",
    "print(\"Baselines\")\n",
    "print(\"u:\", u.shape, \"v:\", v.shape, \"w:\", w.shape)\n",
    "print(\"Frequency\")\n",
    "print(\"freq:\", frequency.shape, \"=\", frequency[0])\n",
    "print(\"LMN\")\n",
    "print(\"l:\", l.shape, \"m:\", m.shape, \"n:\", n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c40b278-74ce-4476-ac8b-8ccdb6700446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "M = 96**2  # Size of each input vector\n",
    "P = npix_l*npix_m  # Number of projections\n",
    "\n",
    "# Create random NumPy inputs\n",
    "baselinesInputNP = np.array([u.flatten(), v.flatten(), w.flatten()]).astype(np.float32) # (3, M)\n",
    "realVisInputNP = visR.flatten().astype(np.float32)       # (M,)\n",
    "imagVisInputNP = visI.flatten().astype(np.float32)       # (M,)\n",
    "factor = -2*frequency[0]*np.pi/SPEED_OF_LIGHT            # scalar\n",
    "scaleNP = np.repeat(factor, P).astype(np.float32)        # (P,)\n",
    "weightsNP = np.array([l.flatten(), m.flatten(), n.flatten()]).astype(np.float32)   # (3, P)\n",
    "\n",
    "# Convert NumPy arrays to PyTorch tensors\n",
    "baselinesInput = torch.from_numpy(baselinesInputNP)\n",
    "realVisInput = torch.from_numpy(realVisInputNP)\n",
    "imagVisInput = torch.from_numpy(imagVisInputNP)\n",
    "scale = torch.from_numpy(scaleNP)\n",
    "weights = torch.from_numpy(weightsNP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ffb555-c505-4a48-8e49-c243e42b18a2",
   "metadata": {},
   "source": [
    "Declaring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "88aa8609-b048-4eb7-9590-2cde6b9abe0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CombinedModule(\n",
       "  (weighted_sum): WeightedSumConv1D(\n",
       "    (conv1d): Conv1d(3, 16384, kernel_size=(1,), stride=(1,), bias=False)\n",
       "  )\n",
       "  (real_imag): RealImagDiffAverage(\n",
       "    (cos): CosineLayer()\n",
       "    (sin): SineLayer()\n",
       "    (mul): ElementwiseMultiply()\n",
       "    (sub): Subtract()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_model = CombinedModule(weights, M)\n",
    "torch_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be961182-d108-4227-8720-504ac178a040",
   "metadata": {},
   "source": [
    "Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5c4cff82-586f-42f1-9c10-15fbc58229cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, input1, input2, scale = (torch.randn(1, 3, M), torch.randn(M), torch.randn(M), torch.randn(P))\n",
    "inputs = {\"x\": x, \"input1\": input1, \"input2\": input2, \"scale\": scale}\n",
    "dynamic_axes = {\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}\n",
    "\n",
    "model_path = \"models/lofty.onnx\"\n",
    "\n",
    "# Call export function\n",
    "torch.onnx.export(\n",
    "        torch_model,\n",
    "        inputs,\n",
    "        model_path,\n",
    "        export_params=True,\n",
    "        opset_version=13,  # Recommended opset\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes=dynamic_axes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54cf8f9b-6508-47ee-be8c-683b37ff5a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "[QUARK-INFO]: The input ONNX model models/lofty.onnx can create InferenceSession successfully\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Random input name input shape [1, 3, 9216] type <class 'numpy.float32'> \u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Random input name onnx::Mul_1 shape [9216] type <class 'numpy.float32'> \u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Random input name onnx::Mul_2 shape [9216] type <class 'numpy.float32'> \u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Random input name onnx::Reshape_3 shape [16384] type <class 'numpy.float32'> \u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Obtained calibration data with 1 iters\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Removed initializers from input\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Simplified model sucessfully\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Duplicate the shared initializers in the model for separate quantization use across different nodes!\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Loading model...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The configuration of the quantization is Config(global_quant_config=QuantizationConfig(calibrate_method=<PowerOfTwoMethod.MinMSE: 1>, quant_format=<QuantFormat.QDQ: 1>, activation_type=<QuantType.QUInt8: 1>, weight_type=<QuantType.QInt8: 0>, input_nodes=[], output_nodes=[], op_types_to_quantize=[], nodes_to_quantize=[], extra_op_types_to_quantize=[], nodes_to_exclude=[], subgraphs_to_exclude=[], specific_tensor_precision=False, execution_providers=['CPUExecutionProvider'], per_channel=False, reduce_range=False, optimize_model=True, use_dynamic_quant=False, use_external_data_format=False, convert_fp16_to_fp32=False, convert_nchw_to_nhwc=False, include_sq=False, include_rotation=False, include_cle=False, include_auto_mp=False, include_fast_ft=False, enable_npu_cnn=True, enable_npu_transformer=False, debug_mode=False, print_summary=True, ignore_warnings=True, log_severity_level=1, extra_options={'ActivationSymmetric': True, 'UseRandomData': True}))\n",
      "[QUARK_INFO]: Time information:\n",
      "2025-06-03 13:03:53.646577\n",
      "[QUARK_INFO]: OS and CPU information:\n",
      "                                        system --- Windows\n",
      "                                          node --- xir-xup-w25\n",
      "                                       release --- 10\n",
      "                                       version --- 10.0.26100\n",
      "                                       machine --- AMD64\n",
      "                                     processor --- AMD64 Family 25 Model 116 Stepping 1, AuthenticAMD\n",
      "[QUARK_INFO]: Tools version information:\n",
      "                                        python --- 3.10.17\n",
      "                                          onnx --- 1.16.1\n",
      "                                   onnxruntime --- 1.20.1\n",
      "                                    quark.onnx --- 0.8+2fc870b\n",
      "[QUARK_INFO]: Quantized Configuration information:\n",
      "                                   model_input --- models/lofty.onnx\n",
      "                                  model_output --- models/lofty_quantized.onnx\n",
      "                       calibration_data_reader --- None\n",
      "                         calibration_data_path --- None\n",
      "                                  quant_format --- QDQ\n",
      "                                   input_nodes --- []\n",
      "                                  output_nodes --- []\n",
      "                          op_types_to_quantize --- []\n",
      "                    extra_op_types_to_quantize --- []\n",
      "                                   per_channel --- False\n",
      "                                  reduce_range --- False\n",
      "                               activation_type --- QUInt8\n",
      "                                   weight_type --- QInt8\n",
      "                             nodes_to_quantize --- []\n",
      "                              nodes_to_exclude --- []\n",
      "                          subgraphs_to_exclude --- []\n",
      "                                optimize_model --- True\n",
      "                      use_external_data_format --- False\n",
      "                              calibrate_method --- PowerOfTwoMethod.MinMSE\n",
      "                           execution_providers --- ['CPUExecutionProvider']\n",
      "                                enable_npu_cnn --- True\n",
      "                        enable_npu_transformer --- False\n",
      "                     specific_tensor_precision --- False\n",
      "                                    debug_mode --- False\n",
      "                          convert_fp16_to_fp32 --- False\n",
      "                          convert_nchw_to_nhwc --- False\n",
      "                                   include_cle --- False\n",
      "                                    include_sq --- False\n",
      "                              include_rotation --- False\n",
      "                               include_fast_ft --- False\n",
      "                                 extra_options --- {'ActivationSymmetric': True, 'UseRandomData': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\n",
      "[QUARK-INFO]: The input ONNX model C:/Users/mruiz/AppData/Local/Temp/vai.cpinit.33lo1k8z/model_cpinit.onnx can run inference successfully\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: optimize the model for better hardware compatibility.\u001b[0m\n",
      "\u001b[33m\n",
      "[QUARK-WARNING]: The opset version is 13 < 17. Skipping fusing layer normalization.\u001b[0m\n",
      "\u001b[33m\n",
      "[QUARK-WARNING]: The opset version is 13 < 20. Skipping fusing Gelu.\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Start calibration...\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Start collecting data, runtime depends on your model size and the number of calibration dataset.\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Finding optimal threshold for each tensor using PowerOfTwoMethod.MinMSE algorithm ...\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Use all calibration data to calculate min mse\u001b[0m\n",
      "Computing range: 100%|██████████| 14/14 [01:31<00:00,  6.53s/tensor]\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Finished the calibration of PowerOfTwoMethod.MinMSE which costs 94.4s\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Remove QuantizeLinear & DequantizeLinear on certain operations(such as conv-relu).\u001b[0m\n",
      "\u001b[33m\n",
      "[QUARK-WARNING]: Do not support rescale ReduceMean /real_imag/ReduceMean to simulate DPU behavior. Please check axes and input shape.\u001b[0m\n",
      "\u001b[32m\n",
      "[QUARK-INFO]: Adjust the quantize info to meet the compiler constraints\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The operation types and their corresponding quantities of the input float model is shown in the table below.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Op Type              </span>┃<span style=\"font-weight: bold\"> Float Model                 </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Conv                 │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Constant             │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 3                           </span>│\n",
       "│ Shape                │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Gather               │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Equal                │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ If                   │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Reshape              │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Mul                  │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 3                           </span>│\n",
       "│ Cos                  │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Sin                  │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ Sub                  │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "│ ReduceMean           │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> 1                           </span>│\n",
       "├──────────────────────┼─────────────────────────────┤\n",
       "│ Quantized model path │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> models/lofty_quantized.onnx </span>│\n",
       "└──────────────────────┴─────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mOp Type             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mFloat Model                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ Conv                 │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Constant             │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m3                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Shape                │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Gather               │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Equal                │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ If                   │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Reshape              │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Mul                  │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m3                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Cos                  │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Sin                  │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Sub                  │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ ReduceMean           │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m1                          \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "├──────────────────────┼─────────────────────────────┤\n",
       "│ Quantized model path │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mmodels/lofty_quantized.onnx\u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "└──────────────────────┴─────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quantized information for all operation types is shown in the table below.\n",
      "The discrepancy between the operation types in the quantized model and the float model is due to the application of graph optimization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Op Type    </span>┃<span style=\"font-weight: bold\"> Activation </span>┃<span style=\"font-weight: bold\"> Weights </span>┃<span style=\"font-weight: bold\"> Bias </span>┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━┩\n",
       "│ Conv       │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> INT8(1) </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ Shape      │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ Mul        │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(3)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ Cos        │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ Sin        │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ Sub        │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "│ ReduceMean │<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\"> UINT8(1)   </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">         </span>│<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">      </span>│\n",
       "└────────────┴────────────┴─────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mOp Type   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mActivation\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mWeights\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mBias\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━┩\n",
       "│ Conv       │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mINT8(1)\u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Shape      │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Mul        │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(3)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Cos        │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Sin        │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ Sub        │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "│ ReduceMean │\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46mUINT8(1)  \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m       \u001b[0m\u001b[1;38;5;46m \u001b[0m│\u001b[1;38;5;46m \u001b[0m\u001b[1;38;5;46m    \u001b[0m\u001b[1;38;5;46m \u001b[0m│\n",
       "└────────────┴────────────┴─────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated and quantized model saved at: models/lofty_quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "# pip install cmake amd-quark (this is how you install quark)\n",
    "from quark.onnx.quantization.config import Config, get_default_config\n",
    "\n",
    "from quark.onnx import ModelQuantizer\n",
    "\n",
    "# `input_model_path` is the path to the original, unquantized ONNX model.\n",
    "input_model_path = \"models/lofty.onnx\"\n",
    "\n",
    "# `output_model_path` is the path where the quantized model will be saved.\n",
    "output_model_path = \"models/lofty_quantized.onnx\"\n",
    "\n",
    "# Use default quantization configuration\n",
    "quant_config = get_default_config(\"XINT8\")\n",
    "quant_config.extra_options[\"UseRandomData\"] = True\n",
    "# Defines the quantization configuration for the whole model\n",
    "config = Config(global_quant_config=quant_config)\n",
    "print(\"The configuration of the quantization is {}\".format(config))\n",
    "\n",
    "# Create an ONNX Quantizer\n",
    "quantizer = ModelQuantizer(config)\n",
    "\n",
    "# Quantize the ONNX model\n",
    "quant_model = quantizer.quantize_model(model_input = input_model_path,\n",
    "                                       model_output = output_model_path,\n",
    "                                       calibration_data_path = None)\n",
    "\n",
    "print('Calibrated and quantized model saved at:', output_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb639a-2be7-4305-917c-f198f26f0c66",
   "metadata": {},
   "source": [
    "Run in CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d6cb7eb-0edb-4aa6-93ac-de0e65c06255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input name: input, shape: ['batch_size', 3, 9216]\n",
      "Input name: onnx::Mul_1, shape: [9216]\n",
      "Input name: onnx::Mul_2, shape: [9216]\n",
      "Input name: onnx::Reshape_3, shape: [16384]\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the quantized ONNZ Model\n",
    "quantized_model_path = r'models/lofty_quantized.onnx' # quatized model doesnt work, but the normal does, weird\n",
    "model = onnx.load(quantized_model_path)\n",
    "\n",
    "# Create some random input data for testing\n",
    "input_data = {\"input\": baselinesInputNP[np.newaxis, :, :], \"onnx::Mul_1\": realVisInputNP, \"onnx::Mul_2\": imagVisInputNP, \"onnx::Reshape_3\": scaleNP}\n",
    "\n",
    "cpu_options = onnxruntime.SessionOptions()\n",
    "\n",
    "# Create Inference Session to run the quantized model on the CPU\n",
    "cpu_session = onnxruntime.InferenceSession(\n",
    "    model.SerializeToString(),\n",
    "    providers = ['CPUExecutionProvider'],\n",
    "    sess_options=cpu_options,\n",
    ")\n",
    "\n",
    "for input_info in cpu_session.get_inputs():\n",
    "    print(f\"Input name: {input_info.name}, shape: {input_info.shape}\")\n",
    "\n",
    "# Run Inference\n",
    "start = timer()\n",
    "cpu_results = cpu_session.run(None, input_data)\n",
    "cpu_total = timer() - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce591e-0bc7-4bd3-9bc9-dd9d8e2f5920",
   "metadata": {},
   "source": [
    "Run in NPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c626f20-9fda-4e1e-a647-19ebbcc0475d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\mruiz\\npucloud_userdata\\antonio-fortanet-capetillo-tudelft\\ryzenaisw\\cache\\hello_cache' does not exist.\n"
     ]
    }
   ],
   "source": [
    "# We want to make sure we compile everytime, otherwise the tools will use the cached version\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "directory_path = os.path.join(current_directory,  r'cache\\hello_cache')\n",
    "cache_directory = os.path.join(current_directory,  r'cache')\n",
    "\n",
    "# Check if the directory exists and delete it if it does.\n",
    "if os.path.exists(directory_path):\n",
    "    shutil.rmtree(directory_path)\n",
    "    print(f\"Directory deleted successfully. Starting Fresh.\")\n",
    "else:\n",
    "    print(f\"Directory '{directory_path}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "def5d0c4-5833-4d80-8430-3f80eb2d3a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeException",
     "evalue": "[ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: private: static void __cdecl google::protobuf::FieldDescriptor::TypeOnceInit(class google::protobuf::FieldDescriptor const * __ptr64)\npublic: virtual unsigned char * __ptr64 __cdecl google::protobuf::internal::ZeroFieldsBase::_InternalSerialize(unsigned char * __ptr64,class google::protobuf::io::EpsCopyOutputStream * __ptr64)const __ptr64\n__CxxFrameHandler4\n(unknown)\nRtlCaptureContext2\npublic: static class vaip_core::ConfigProto __cdecl vaip_core::Config::parse_from_string(char const * __ptr64)\nclass std::vector<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vaip_core::ExecutionProvider> >,class std::allocator<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vai\nclass std::vector<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vaip_core::ExecutionProvider> >,class std::allocator<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vai\ncompile_onnx_model_vitisai_ep_with_error_handling\n(unknown)\n(unknown)\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\npublic: void __cdecl pybind11::error_already_set::discard_as_unraisable(class pybind11::object) __ptr64\nPyCFunction_GetFlags\n_PyObject_MakeTpCall\nPyMethod_Self\n_PyOS_URandomNonblock\nPyEval_GetFuncDesc\n_PyEval_EvalFrameDefault\n_PyEval_EvalFrameDefault\n_PyFunction_Vectorcall\n_PyOS_URandomNonblock\nPyEval_GetFuncDesc\n_PyEval_EvalFrameDefault\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeException\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m config_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(install_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoe-4.0-win_amd64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvaip_config.json\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Path to the NPU config file\u001b[39;00m\n\u001b[0;32m      4\u001b[0m aie_options \u001b[38;5;241m=\u001b[39m onnxruntime\u001b[38;5;241m.\u001b[39mSessionOptions()\n\u001b[1;32m----> 6\u001b[0m aie_session \u001b[38;5;241m=\u001b[39m \u001b[43monnxruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSerializeToString\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproviders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVitisAIExecutionProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43msess_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maie_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconfig_file\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcacheDir\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcacheKey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhello_cache\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:465\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[1;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m disabled_optimizers \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisabled_optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 465\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_inference_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "File \u001b[1;32m~\\.conda\\envs\\antonio-fortanet-capetillo-tudelft\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:537\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[1;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[0;32m    534\u001b[0m     disabled_optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(disabled_optimizers)\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[1;32m--> 537\u001b[0m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproviders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprovider_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisabled_optimizers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m sess\n\u001b[0;32m    540\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_options \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess\u001b[38;5;241m.\u001b[39msession_options\n",
      "\u001b[1;31mRuntimeException\u001b[0m: [ONNXRuntimeError] : 6 : RUNTIME_EXCEPTION : Exception during initialization: private: static void __cdecl google::protobuf::FieldDescriptor::TypeOnceInit(class google::protobuf::FieldDescriptor const * __ptr64)\npublic: virtual unsigned char * __ptr64 __cdecl google::protobuf::internal::ZeroFieldsBase::_InternalSerialize(unsigned char * __ptr64,class google::protobuf::io::EpsCopyOutputStream * __ptr64)const __ptr64\n__CxxFrameHandler4\n(unknown)\nRtlCaptureContext2\npublic: static class vaip_core::ConfigProto __cdecl vaip_core::Config::parse_from_string(char const * __ptr64)\nclass std::vector<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vaip_core::ExecutionProvider> >,class std::allocator<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vai\nclass std::vector<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vaip_core::ExecutionProvider> >,class std::allocator<class std::unique_ptr<class vaip_core::ExecutionProvider,struct std::default_delete<class vai\ncompile_onnx_model_vitisai_ep_with_error_handling\n(unknown)\n(unknown)\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\nPyInit_onnxruntime_pybind11_state\npublic: void __cdecl pybind11::error_already_set::discard_as_unraisable(class pybind11::object) __ptr64\nPyCFunction_GetFlags\n_PyObject_MakeTpCall\nPyMethod_Self\n_PyOS_URandomNonblock\nPyEval_GetFuncDesc\n_PyEval_EvalFrameDefault\n_PyEval_EvalFrameDefault\n_PyFunction_Vectorcall\n_PyOS_URandomNonblock\nPyEval_GetFuncDesc\n_PyEval_EvalFrameDefault\n"
     ]
    }
   ],
   "source": [
    "install_dir = os.environ['RYZEN_AI_INSTALLATION_PATH']\n",
    "config_file_path = os.path.join(install_dir, 'voe-4.0-win_amd64', 'vaip_config.json') # Path to the NPU config file\n",
    "\n",
    "aie_options = onnxruntime.SessionOptions()\n",
    "\n",
    "aie_session = onnxruntime.InferenceSession(\n",
    "    model.SerializeToString(),\n",
    "    providers=['VitisAIExecutionProvider'],\n",
    "    sess_options=aie_options,\n",
    "    provider_options = [{'config_file': config_file_path,\n",
    "                         'cacheDir': cache_directory,\n",
    "                         'cacheKey': 'hello_cache'}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f2b97a1-95b0-4b29-8836-66411e616de0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aie_session' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Run Inference\u001b[39;00m\n\u001b[0;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m----> 3\u001b[0m npu_results \u001b[38;5;241m=\u001b[39m \u001b[43maie_session\u001b[49m\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mNone\u001b[39;00m, input_data)\n\u001b[0;32m      4\u001b[0m npu_total \u001b[38;5;241m=\u001b[39m timer() \u001b[38;5;241m-\u001b[39m start\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aie_session' is not defined"
     ]
    }
   ],
   "source": [
    "# Run Inference\n",
    "start = timer()\n",
    "npu_results = aie_session.run(None, input_data)\n",
    "npu_total = timer() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504623fc-402c-4143-9284-c44cc7d33e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
